# ReSpAct: Harmonizing Reasoning, Speaking, and Acting
[![Paper](https://img.shields.io/badge/arXiv-Paper-red.svg)]()

**[ReSpAct: Harmonizing Reasoning, Speaking, and Acting Towards Building Large Language Model-Based Conversational AI Agents](https://vardhandongre.github.io/respact-llm/)**  
[Vardhan Dongre](https://vardhandongre.github.io/), [Xiaocheng Yang](https://www.linkedin.com/in/xiaocheng-yang-1a68aa20b?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADVY_o4B3amA3qxReMk8okt2Vk9XjaRcS0g&lipi=urn%3Ali%3Apage%3Ad_flagship3_search_srp_all%3B%2FelJ2zYqRVuwEdBXgxKDEw%3D%3D), [Emre Can Acikgoz](https://emrecanacikgoz.github.io/), [Suvodip Dey](https://scholar.google.com/citations?user=cCFhUMwAAAAJ&hl=en), [Gokhan Tur](https://siebelschool.illinois.edu/about/people/faculty/gokhan), [Dilek Hakkani-TÃ¼r](https://siebelschool.illinois.edu/about/people/faculty/dilek)

<p float="left">
  <img src="assets/diagram.gif">
</p>

This repository contains code for reproducing results. If you find this work useful in your research, please cite:

```
@inproceedings{yao2022webshop,
  bibtex_show = {true},
  title = {ReSpAct: Harmonizing Reasoning, Speaking, and Acting Towards Building Large Language Model-Based Conversational AI Agents},
  author = {},
  booktitle = {ArXiv},
  year = {preprint},
  html = {},
  tag = {NLP}
}
```

## Quickstart

Create a virtual environment (recommended)

    conda create -n respact python=3.12
    conda activate respact
    pip install -r requirements.txt

## :hammer_and_pick: Environment Setup
## Alfworld

> [!WARNING]  
> If you are using MacOS with an arm-based system, it is recommended to use
> 
    CONDA_SUBDIR=osx-64 conda create -n alfworld python=3.12
    conda activate alfworld

Install with pip (python3.9+):

    pip install alfworld

Download PDDL & Game files and pre-trained MaskRCNN detector:
```bash
export ALFWORLD_DATA=<storage_path>
alfworld-download
```
## Run ReSpAct Experiments
```bash
export OPENAI_API_KEY=<key>
```
For Azure:
```bash
export AZURE_OPENAI_ENDPOINT=<endpoint>
export AZURE_OPENAI_KEY=<key>
```
The experiments are controlled via two yaml files, `base_config.yaml` to control the alfworld games and `experiment_configs.yaml` for the respact experimentation. 

    python main.py
    
## ðŸ›’ WebShop
## ðŸš€ Setup
Our code is implemented in Python. To setup, do the following:
1. Install [Python 3.8.13](https://www.python.org/downloads/release/python-3813/)
2. Install [Java](https://www.java.com/en/download/)
3. Download the source code:
```sh
> git clone https://github.com/princeton-nlp/webshop.git webshop
```
4. Create a virtual environment using [Anaconda](https://anaconda.org/anaconda/python) and activate it
```sh
> conda create -n webshop python=3.8.13
> conda activate webshop
```
5. Install requirements into the `webshop` virtual environment via the `setup.sh` script
```sh
> ./setup.sh [-d small|all]
```
The setup script performs several actions in the following order:
* Installs Python dependencies listed in `requirements.txt`
* Downloads product and instruction data for populating WebShop
* Downloads `spaCy en_core_web_lg` model
* Construct search engine index from product, instruction data
* Downloads 50 randomly chosen trajectories generated by MTurk workers
The `-d` flag argument allows you to specify whether you would like to pull the entire product + instruction data set (`-d all`) or a subset of 1000 random products (`-d small`).

6. By default the WebShop only loads 1,000 products for a faster environment preview. To load all products, change `web_agent_site/utils.py`:
```python
# DEFAULT_ATTR_PATH = join(BASE_DIR, '../data/items_ins_v2_1000.json')
# DEFAULT_FILE_PATH = join(BASE_DIR, '../data/items_shuffle_1000.json')
DEFAULT_ATTR_PATH = join(BASE_DIR, '../data/items_ins_v2.json')
DEFAULT_FILE_PATH = join(BASE_DIR, '../data/items_shuffle.json')
```

## ðŸ› ï¸ Usage
The WebShop environment can be rendered in two modes - `html` and `simple` - each of which offer a different observation space. The `simple` mode strips away the extraneous meta-data that the `html` mode includes to make model training and evaluation easier.
### Webpage Environment (`html` mode)
Launch the `WebShop` webpage:
```sh
> ./run_dev.sh
```
The site should then be viewable in the browser. Go to http://localhost:3000/ABC, where you should land on the search home page with a random instruction.





## MultiWOZ
To-Do
